{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"accelerator":"GPU","language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from __future__ import print_function\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms","metadata":{"id":"0m2JWFliFfKT","execution":{"iopub.status.busy":"2024-03-02T01:45:40.854964Z","iopub.execute_input":"2024-03-02T01:45:40.855605Z","iopub.status.idle":"2024-03-02T01:45:44.255175Z","shell.execute_reply.started":"2024-03-02T01:45:40.855572Z","shell.execute_reply":"2024-03-02T01:45:44.254376Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"class MyNet(nn.Module):\n  def __init__(self):\n    super(MyNet,self).__init__()\n    self.block1 = nn.Sequential(\n        nn.Conv2d(1,12,3,padding=1),\n        nn.ReLU(),\n        nn.BatchNorm2d(12),\n        nn.Dropout2d(0.1),\n        nn.Conv2d(12,16,3,padding=1),\n        nn.ReLU(),\n        nn.BatchNorm2d(16),\n        nn.MaxPool2d(2,2),\n        nn.Dropout2d(0.1)\n     )\n\n    self.block2 = nn.Sequential(\n        nn.Conv2d(16,20,3,padding=1),\n        nn.ReLU(),\n        nn.BatchNorm2d(20),\n        nn.Dropout2d(0.1),\n        nn.Conv2d(20,28,3,padding=1),\n        nn.ReLU(),\n        nn.BatchNorm2d(28),\n        nn.MaxPool2d(2,2),\n        nn.Dropout2d(0.1)\n\n    )\n\n    self.block3 = nn.Sequential(\n        nn.Conv2d(28,24,3),\n        nn.ReLU(),\n        nn.BatchNorm2d(24),\n        nn.Dropout2d(0.1),\n        nn.Conv2d(24,12,3),\n        nn.ReLU(),\n        nn.BatchNorm2d(12)\n    )\n\n    self.fc = nn.Linear(108,10)\n\n  def forward(self, x):\n    x = self.block1(x)\n    x = self.block2(x)\n    x = self.block3(x)\n    x = x.view(-1, 108)\n    x = self.fc(x)\n    x = F.log_softmax(x, dim=1)\n    return x\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","metadata":{"id":"0dhSb31V5osA","execution":{"iopub.status.busy":"2024-03-02T01:45:44.257395Z","iopub.execute_input":"2024-03-02T01:45:44.258124Z","iopub.status.idle":"2024-03-02T01:45:44.268618Z","shell.execute_reply.started":"2024-03-02T01:45:44.258089Z","shell.execute_reply":"2024-03-02T01:45:44.267781Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 16, 3, padding=1) #input -? OUtput? RF\n        self.conv2 = nn.Conv2d(16, 20, 3, padding=1)\n        self.pool1 = nn.MaxPool2d(2, 2)\n        self.conv3 = nn.Conv2d(20, 24, 3, padding=1)\n        self.conv4 = nn.Conv2d(24, 28, 3, padding=1)\n        self.pool2 = nn.MaxPool2d(2, 2)\n        self.conv5 = nn.Conv2d(28, 14, 3)\n        self.conv6 = nn.Conv2d(14, 12, 3)\n        self.conv7 = nn.Conv2d(12, 10, 3)\n\n    def forward(self, x):\n        x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x)))))\n        x = self.pool2(F.relu(self.conv4(F.relu(self.conv3(x)))))\n        x = F.relu(self.conv6(F.relu(self.conv5(x))))\n        x = F.relu(self.conv7(x))\n        x = x.view(-1, 10)\n        return F.log_softmax(x)","metadata":{"id":"h_Cx9q2QFgM7","execution":{"iopub.status.busy":"2024-03-02T01:45:44.269855Z","iopub.execute_input":"2024-03-02T01:45:44.270169Z","iopub.status.idle":"2024-03-02T01:45:44.285591Z","shell.execute_reply.started":"2024-03-02T01:45:44.270146Z","shell.execute_reply":"2024-03-02T01:45:44.284871Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!pip install torchsummary\nfrom torchsummary import summary\nuse_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda\" if use_cuda else \"cpu\")\nmodel = MyNet().to(device)\nsummary(model, input_size=(1, 28, 28))","metadata":{"id":"xdydjYTZFyi3","colab":{"base_uri":"https://localhost:8080/"},"outputId":"135e8120-0f57-45b9-ec4f-84e999565621","execution":{"iopub.status.busy":"2024-03-02T01:45:44.287844Z","iopub.execute_input":"2024-03-02T01:45:44.291349Z","iopub.status.idle":"2024-03-02T01:45:56.855133Z","shell.execute_reply.started":"2024-03-02T01:45:44.291315Z","shell.execute_reply":"2024-03-02T01:45:56.854126Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchsummary in /opt/conda/lib/python3.10/site-packages (1.5.1)\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 12, 28, 28]             120\n              ReLU-2           [-1, 12, 28, 28]               0\n       BatchNorm2d-3           [-1, 12, 28, 28]              24\n         Dropout2d-4           [-1, 12, 28, 28]               0\n            Conv2d-5           [-1, 16, 28, 28]           1,744\n              ReLU-6           [-1, 16, 28, 28]               0\n       BatchNorm2d-7           [-1, 16, 28, 28]              32\n         MaxPool2d-8           [-1, 16, 14, 14]               0\n         Dropout2d-9           [-1, 16, 14, 14]               0\n           Conv2d-10           [-1, 20, 14, 14]           2,900\n             ReLU-11           [-1, 20, 14, 14]               0\n      BatchNorm2d-12           [-1, 20, 14, 14]              40\n        Dropout2d-13           [-1, 20, 14, 14]               0\n           Conv2d-14           [-1, 28, 14, 14]           5,068\n             ReLU-15           [-1, 28, 14, 14]               0\n      BatchNorm2d-16           [-1, 28, 14, 14]              56\n        MaxPool2d-17             [-1, 28, 7, 7]               0\n        Dropout2d-18             [-1, 28, 7, 7]               0\n           Conv2d-19             [-1, 24, 5, 5]           6,072\n             ReLU-20             [-1, 24, 5, 5]               0\n      BatchNorm2d-21             [-1, 24, 5, 5]              48\n        Dropout2d-22             [-1, 24, 5, 5]               0\n           Conv2d-23             [-1, 12, 3, 3]           2,604\n             ReLU-24             [-1, 12, 3, 3]               0\n      BatchNorm2d-25             [-1, 12, 3, 3]              24\n           Linear-26                   [-1, 10]           1,090\n================================================================\nTotal params: 19,822\nTrainable params: 19,822\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.91\nParams size (MB): 0.08\nEstimated Total Size (MB): 0.99\n----------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\ntorch.manual_seed(1)\nbatch_size = 128\n\nkwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\ntrain_loader = torch.utils.data.DataLoader(\n    datasets.MNIST('../data', train=True, download=True,\n                    transform=transforms.Compose([\n                        transforms.ToTensor(),\n                        transforms.Normalize((0.1307,), (0.3081,))\n                    ])),\n    batch_size=batch_size, shuffle=True, **kwargs)\ntest_loader = torch.utils.data.DataLoader(\n    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n                        transforms.ToTensor(),\n                        transforms.Normalize((0.1307,), (0.3081,))\n                    ])),\n    batch_size=batch_size, shuffle=True, **kwargs)\n","metadata":{"id":"DqTWLaM5GHgH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"245aab83-54c0-45ef-e494-1435f0f723a1","execution":{"iopub.status.busy":"2024-03-02T01:45:56.856432Z","iopub.execute_input":"2024-03-02T01:45:56.856728Z","iopub.status.idle":"2024-03-02T01:45:58.257379Z","shell.execute_reply.started":"2024-03-02T01:45:56.856699Z","shell.execute_reply":"2024-03-02T01:45:58.256348Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 9912422/9912422 [00:00<00:00, 99478655.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 28881/28881 [00:00<00:00, 44666553.77it/s]","output_type":"stream"},{"name":"stdout","text":"Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1648877/1648877 [00:00<00:00, 23209402.70it/s]","output_type":"stream"},{"name":"stdout","text":"Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4542/4542 [00:00<00:00, 19088706.18it/s]","output_type":"stream"},{"name":"stdout","text":"Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"from tqdm import tqdm\ndef train(model, device, train_loader, optimizer, epoch):\n    model.train()\n    pbar = tqdm(train_loader)\n    for batch_idx, (data, target) in enumerate(pbar):\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.nll_loss(output, target)\n        loss.backward()\n        optimizer.step()\n        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n\n\ndef test(model, device, test_loader):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n            correct += pred.eq(target.view_as(pred)).sum().item()\n\n    test_loss /= len(test_loader.dataset)\n\n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))","metadata":{"id":"8fDefDhaFlwH","execution":{"iopub.status.busy":"2024-03-02T01:45:58.258937Z","iopub.execute_input":"2024-03-02T01:45:58.259242Z","iopub.status.idle":"2024-03-02T01:45:58.268618Z","shell.execute_reply.started":"2024-03-02T01:45:58.259216Z","shell.execute_reply":"2024-03-02T01:45:58.267739Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"\nmodel = MyNet().to(device)\noptimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n\nfor epoch in range(1, 19):\n    train(model, device, train_loader, optimizer, epoch)\n    test(model, device, test_loader)","metadata":{"id":"MMWbLWO6FuHb","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a87bda66-53ff-4f90-d31d-6af79486877e","execution":{"iopub.status.busy":"2024-03-02T01:45:58.269916Z","iopub.execute_input":"2024-03-02T01:45:58.270435Z","iopub.status.idle":"2024-03-02T01:50:51.096515Z","shell.execute_reply.started":"2024-03-02T01:45:58.270409Z","shell.execute_reply":"2024-03-02T01:50:51.095375Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"loss=0.13429321348667145 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 32.44it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0508, Accuracy: 9846/10000 (98.46%)\n\n","output_type":"stream"},{"name":"stderr","text":"loss=0.056530725210905075 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 32.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0359, Accuracy: 9882/10000 (98.82%)\n\n","output_type":"stream"},{"name":"stderr","text":"loss=0.03811878338456154 batch_id=468: 100%|██████████| 469/469 [00:13<00:00, 34.06it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0271, Accuracy: 9906/10000 (99.06%)\n\n","output_type":"stream"},{"name":"stderr","text":"loss=0.0275739673525095 batch_id=468: 100%|██████████| 469/469 [00:13<00:00, 33.56it/s]  \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0285, Accuracy: 9903/10000 (99.03%)\n\n","output_type":"stream"},{"name":"stderr","text":"loss=0.00799736101180315 batch_id=468: 100%|██████████| 469/469 [00:13<00:00, 33.62it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0229, Accuracy: 9921/10000 (99.21%)\n\n","output_type":"stream"},{"name":"stderr","text":"loss=0.060897260904312134 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 33.47it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0242, Accuracy: 9919/10000 (99.19%)\n\n","output_type":"stream"},{"name":"stderr","text":"loss=0.05599065124988556 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 33.49it/s]  \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0208, Accuracy: 9932/10000 (99.32%)\n\n","output_type":"stream"},{"name":"stderr","text":"loss=0.015218880027532578 batch_id=468: 100%|██████████| 469/469 [00:13<00:00, 33.94it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0239, Accuracy: 9924/10000 (99.24%)\n\n","output_type":"stream"},{"name":"stderr","text":"loss=0.002427784027531743 batch_id=468: 100%|██████████| 469/469 [00:13<00:00, 33.58it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0199, Accuracy: 9929/10000 (99.29%)\n\n","output_type":"stream"},{"name":"stderr","text":"loss=0.004111432004719973 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 33.41it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0222, Accuracy: 9929/10000 (99.29%)\n\n","output_type":"stream"},{"name":"stderr","text":"loss=0.04143816977739334 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 33.04it/s]  \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0225, Accuracy: 9924/10000 (99.24%)\n\n","output_type":"stream"},{"name":"stderr","text":"loss=0.0036035676021128893 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 33.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0196, Accuracy: 9936/10000 (99.36%)\n\n","output_type":"stream"},{"name":"stderr","text":"loss=0.007966360077261925 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 33.33it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0206, Accuracy: 9928/10000 (99.28%)\n\n","output_type":"stream"},{"name":"stderr","text":"loss=0.02171838842332363 batch_id=468: 100%|██████████| 469/469 [00:13<00:00, 34.02it/s]  \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0189, Accuracy: 9941/10000 (99.41%)\n\n","output_type":"stream"},{"name":"stderr","text":"loss=0.01689746417105198 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 33.21it/s]  \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0177, Accuracy: 9940/10000 (99.40%)\n\n","output_type":"stream"},{"name":"stderr","text":"loss=0.016957690939307213 batch_id=468: 100%|██████████| 469/469 [00:13<00:00, 33.81it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0176, Accuracy: 9935/10000 (99.35%)\n\n","output_type":"stream"},{"name":"stderr","text":"loss=0.05067889764904976 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 33.09it/s]  \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0178, Accuracy: 9942/10000 (99.42%)\n\n","output_type":"stream"},{"name":"stderr","text":"loss=0.030904436483979225 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 33.47it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nTest set: Average loss: 0.0186, Accuracy: 9939/10000 (99.39%)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"So5uk4EkHW6R"},"execution_count":null,"outputs":[]}]}